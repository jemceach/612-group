{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data 612 - Research Discussion 2 <br> Juliann McEachern  <br> June 20, 2019\n",
    "\n",
    "## <center>Music Recommendations</center>\n",
    "\n",
    "### Prompt: \n",
    "For this discussion item, please watch the following talk and summarize what you found to be the most important or interesting points. The first half will cover some of the mathematical techniques covered in this unit's reading and the second half some of the data management challenges in an industrial-scale recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/3LBgiFch4_g\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/3LBgiFch4_g\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post:\n",
    "\n",
    "#### Spotify Recommender System Overview\n",
    "\n",
    "Spotify allows users to search for any song, genre, or album. Their audio collection contains over 40 million songs and the company implores different methods to recommend their streaming content to users. They build personalized recommendations by analyzing what users might want to listen to, and even offer radio stations based off artist and can suggest related artists to users. \n",
    "\n",
    "Spotify recently acquired a company that uses audio content, metadata, and text analysis of songs and artists to build recommendations. However, their historical approach (and the focus of the talk, was collaborative filtering. The presenter started with a broad overview of this type of recommender system. In short, Spotify analyzes user listening patterns and makes recommendations off of those relationships.\n",
    "\n",
    "#### Explicit vs Implicit Matrix Factoring \n",
    "\n",
    "We learned a lot in Data 620 about explicit matrix factoring in our Project 1 and 2 recommender system attempts. In the Spotify talk, the presenter covers a different way for us to consider when building collaborative recommenders, based on implicit matrix factorization. Unlike explicit matrix factoring, which relies on user ratings, Spotify infers user preferences and uses binary labels to code the data. \n",
    "\n",
    "Their method captures whether or not a user streamed a song using 1 for streamed and 0 for never streamed on their services. Implicit matrix factoring is calculated similarly to explicit factoring, however this model weights the total number of user streams in their function, with the goal of minimizing the weighted RMSE. \n",
    "\n",
    "The presenter then talks about different methods to solve the matrix. He first discussed alternating least squares to solve to alternate between solving for the user vectors and song vectors. This method requires constant iteration to continuously solve this algorithm. And, Spotify ran into input/output performance issues when loading and reading the matrices files in Hadoop. Spotify later transitioned to Spark, which solved this overload issue by loading the matrices into memory and caching the output. \n",
    "\n",
    "#### Key Take-Aways: \n",
    "\n",
    "Matrix calculations are expansive especially in a non-static, operational environment. My biggest take away here is the importance of processor speeds and memory capabilities for developers in all aspects of the data transaction processes. Spotify solved this problem for their platform by transitioning their framework from Hadoop to Spark. As a result, they were able to drastically reduce their processing speeds for ALS calculations from 10 hours with Hadoop to 1.5 hours with Spark.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
