{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data 612 - Research Discussion 4<br> Juliann McEachern  <br> July 7, 2019\n",
    "\n",
    "<h1 align=\"center\">Mitigating the Harm of Recommender Systems</h1>\n",
    "\n",
    "## Prompt:\n",
    "\n",
    "Read one or more of the articles below and consider how to counter the radicalizing effects of recommender systems or ways to prevent algorithmic discrimination.\n",
    "\n",
    "1. Renee Diresta, Wired.com (2018): [Up Next: A Better Recommendation System](https://www.wired.com/story/creating-ethical-recommendation-engines/)\n",
    "2. Zeynep Tufekci, The New York Times (2018): [YouTube, the Great Radicalizer](https://www.nytimes.com/2018/03/10/opinion/sunday/youtube-politics-radical.html)\n",
    "3. Sanjay Krishnan, Jay Patel, Michael J. Franklin, Ken Goldberg (n/a): [Social Influence Bias in Recommender Systems: A Methodology for Learning, Analyzing, and Mitigating Bias in Ratings](https://goldberg.berkeley.edu/pubs/sanjay-recsys-v10.pdf)\n",
    "\n",
    "----------------------------------\n",
    "\n",
    "## Response: \n",
    "\n",
    "The radicalizing effect of recommender systems is a growing concern that is not easily dealt with. Recommender systems are used by any group with searchable content. The goal of these systems is to recommend products and services that its users would be interested in. Whether it's an entertainment site like Netflix, Hulu, or Youtube, or an online store like Amazon or Ebay, or a social media app like Facebook or Twitter, their goal is the same, to make money. The recommender systems are essential to keeping customers rooted to their site. The algorithms being used are becoming more and more intelligent. They're not only working to display products that a user has already shown interest in, but actively trying to predict what a user will want next. This becomes a problem with sites like YouTube because the algorithm has determined that what keeps people interested is \"incendiary content\". YouTube's recommender system will continually supply its users with videos that escalate in severity. We as humans want to know more, we want to follow the rabbit hole deeper and deeper, and these algorithms play on that desire, often to a negative effect on the user's wellbeing.\n",
    "\n",
    "These same algorithms could be used in the exact opposite way. They could be used to direct us away from these deep dives into subjects that would be better left alone. The problem is that it's much harder to develop and maintain an algorithm that is smart enough to not only learn what a user wants, but also what that content actually is. The way most of these systems work, they're able to supply the recommendations, but without understanding what they're recommending. There's no concern for whether the content is harmful to the user or society as a whole. Many people are being wrongly informed about any number of topics purely because their searches have been lead by recommender systems that have no regard for the content they're recommending. \n",
    "\n",
    "The only way to combat this growing problem is for companies to start putting the wellbeing of their customers and the wellbeing of society before their profits. The algorithms could be developed to take into consideration what would be good and healthy for a user, but that system would cost more to build and maintain while actively leading users away from content that could keep them on a particular site. Beyond financial ramifications, this also leads into First Amendment territory. If a company actively deters you from content it deems unsafe, people shout censorship. The sad truth is, our content is already being censored, but in a way that does much more harm than good. Honest content is being pushed aside because the recommender systems believe it lacks the conflict necessary to keep people interested. \n",
    "\n",
    "Companies aren't going to make the change to healthier recommender systems on their own. Only with some type of government regulations are they going to set aside potential profit for the benefit of others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
