---
title: "Project 4: Accuracy and Beyond in Restaurant Recommender Systems"
author: "Christina Valore, Juliann McEachern, & Rajwant Mishra"
date: "July 2, 2019"
output:
  prettydoc::html_pretty:
    theme: leonids 
    highlight: github
---

```{r dependencies, echo=F,comment=F,message=F,warning=F,prompt=F}
# data processing
library(tidyr); library(dplyr); library(RCurl); library(jsonlite); library(plyr)

#formatting
library(knitr); library(kableExtra); library(prettydoc); library(default)

#visualization
library(ggplot2)

#recommender 
library(recommenderlab)

# global options
## knit sizing
options(max.print="75"); opts_knit$set(width=75) 

## augment chunk output
opts_chunk$set(echo=F,cache=F, tidy=T,comment=F,message=T,warning=T) #change message/warning to F upon completion

## set table style for consistency
default(kable_styling)  <- list(bootstrap_options=c("basic"),position="center",full_width=T, font_size=10)

## working directory
##try(setwd("~/Github/612-group/project-4"))
```


# Overview

The goal of this assignment is give you practice working with accuracy and other recommender system metrics. 

Tasks:

1. Compare the accuracy of at least two recommender system algorithms against your offline data. 
2. Compare and report on any change in accuracy before and after you've made the change in the algorithms. 
3. Include at least one business or user experience goal such as increased serendipity, novelty, or diversity. 
4. Textual conclusion

## Data Selection

Our data was sourced from Kaggle's [Restaurant Data with Consumer Ratings](https://www.kaggle.com/uciml/restaurant-data-with-consumer-ratings) collection, which contained several datasets pertaining to restaurants and their patrons. The csv files are stored within our repository in the data folder. 

```{r}
data1<-read.csv("https://raw.githubusercontent.com/jemceach/612-group/master/project-4/data/chefmozcuisine.csv") # cusine tags
data2<-read.csv("https://raw.githubusercontent.com/jemceach/612-group/master/project-4/data/geoplaces2.csv") # restaurant name
data3<-read.csv("https://raw.githubusercontent.com/jemceach/612-group/master/project-4/data/rating_final.csv") # user ratings
data4<-read.csv("https://raw.githubusercontent.com/jemceach/612-group/master/project-4/data/userprofile.csv") # user profile
```

## Data Tranformations

We cleaned our data using transformations and regular expression unite our user and restaurant data into a user item matrix. 

**GROUP NOTES** (DELETE LATER):

*  3 Matrices are defined. 1 has null values, 1 is imputed with the mean, 1 is imputed with 0. 
*  Dataset includes many interesting categorical features. We could try 2 user-item algorthims and a hybrid approach.
*  Lets try to do our best to minimize code chunks, add explanitory text for readers/within code chunks for us to follow.
*  Add/reference sources at the end! 

```{r}
## restaurant dataframe
restaurant <- data2 %>% select(placeID, name, city,price,franchise, alcohol,smoking_area) %>% mutate(name=tolower(gsub("[\u00ef\u00bf\u00bd\'_']", " ", name))) %>% mutate(city=tolower(city))
restaurant$price <- factor(restaurant$price, levels = c("low", "medium", "high")) # set factor
restaurant$city <- revalue(restaurant$city, c("cd victoria"="ciudad victoria", "cd. victoria"="ciudad victoria","victoria "="ciudad victoria","victoria"="ciudad victoria","san luis potosi "="san luis potosi","san luis potos"="san luis potosi","s.l.p"="san luis potosi","slp"="san luis potosi","s.l.p."="san luis potosi"))
restaurant$city<-factor(restaurant$city, exclude = NULL)


## user dataframe: select attributes of interest from profile
user_profile <- data4 %>% select(userID, birth_year,budget,activity, drink_level)
user <- inner_join(data3,user_profile,by='userID') 
user$budget <- factor(user$budget, levels = c("low", "medium", "high")) # set factor

## change ratings from 0-2 scale to 1-3
user$rating[user$rating==2]<-3;user$rating[user$rating==1]<-2;user$rating[user$rating==0]<-1
user$service_rating[user$service_rating==2]<-3;user$service_rating[user$service_rating==1]<-2;user$service_rating[user$service_rating==0]<-1
user$food_rating[user$food_rating==2]<-3;user$food_rating[user$food_rating==1]<-2;user$food_rating[user$food_rating==0]<-1;

# combine user and restaurant
data <- inner_join(user, restaurant, by="placeID") 

# subset 
data <- data %>% filter(city == "san luis potosi", activity=="student")
```


## Data Exploration

We found that 80% of our raters were students students and 76% of our restaurants were located within the Mexican city of San Luis Potosi.  As a result, we subsetted our restaurant/patron data to limit the scope of our system to this specific population. After subsetting our raw data, we identified 78 unique users and 74 restaurants to build our recommender systems from. 

The folloing plots show the distribution of our ratings by patron budget and restaurant pricing. We can also see counts of ratings each restaurant received. On average, each venue received 13 ratings. 

```{r}
ggplot(data, aes(x=rating)) + geom_histogram(bins=3, color='#000000', fill='#e4d1d1') +labs(title="Raw Ratings Distribution by Patron Budget") + facet_wrap(data$budget, nrow=1)

ggplot(data, aes(x=rating)) + geom_histogram(bins=3, color='#000000', fill='#b9b0b0') +labs(title="Raw Ratings Distribution by Restaurant Pricing") + facet_wrap(data$price, nrow=1)

data %>% mutate(placeID = as.factor(placeID), rating=as.factor(rating)) %>% group_by(placeID) %>% add_tally() %>% ungroup() %>% ggplot(aes(x=reorder(placeID, -n),fill=rating))+ geom_bar(stat="count", color="#686256") + theme(axis.title.x=element_blank(),axis.text.x=element_blank(),axis.ticks.x=element_blank())+labs(title="Restaurant Rating Counts") + scale_fill_manual(values=c("#f0efef", "#e4d1d1", "#b9b0b0"))
```


# Matrix Building 

```{r}
## create user item matrix

ui_matrix <- data %>% select(userID, placeID, rating) %>% spread(placeID, rating)

## build two frames for comparison - mu = mean ratings imputation; na = imputed with 0 
ui_mtx_mu <- ui_matrix; ui_mtx_na <- ui_matrix 

for(i in c(2:75)){
  ui_mtx_mu[is.na(ui_mtx_mu[,i]), i] <- round(mean(ui_mtx_mu[,i], na.rm = TRUE))
}

ui_mtx_na[is.na(ui_mtx_na)] <- 0

## preview matrices (DELETE LATER)
ui_matrix; ui_mtx_mu; ui_mtx_na
```

# Training and Test Subsets
```{r}
umat<-as.matrix(ui_matrix)
umat <- as(umat,"realRatingMatrix")

evalu <- evaluationScheme(umat, method="split", train=0.8, given=5, goodRating=0)
```


# Collaborative Filtering 

Business/User Goal: Serendipity

Recommend relevant items to targeted users that are different then items the user has already rated. 

## Algorithm 1: User-Based with Method: Cosine
```{r}
#Method: Cosine

#non-normalized
UBCF_N_C <- Recommender(getData(evalu, "train"), "UBCF", 
      param=list(normalize = NULL, method="Cosine"))

#centered
UBCF_C_C <- Recommender(getData(evalu, "train"), "UBCF", 
      param=list(normalize = "center",method="Cosine"))

#Z-score normalization
UBCF_Z_C <- Recommender(getData(evalu, "train"), "UBCF", 
      param=list(normalize = "Z-score",method="Cosine"))
```

```{r}
#predicted ratings
p1 <- predict(UBCF_N_C, getData(evalu, "known"), type="ratings")

p2 <- predict(UBCF_C_C, getData(evalu, "known"), type="ratings")

p3 <- predict(UBCF_Z_C, getData(evalu, "known"), type="ratings")

#ceiling and floor values
p1@data@x[p1@data@x[] < 1] <- 1
p1@data@x[p1@data@x[] > 3] <- 3

p2@data@x[p2@data@x[] < 1] <- 1
p2@data@x[p2@data@x[] > 3] <- 3

p3@data@x[p3@data@x[] < 1] <- 1
p3@data@x[p3@data@x[] > 3] <- 3

#compare the predictions using the different normalize methongs
error_UCOS <- rbind(
  UBCF_N_C = calcPredictionAccuracy(p1, getData(evalu, "unknown")),
  UBCF_C_C = calcPredictionAccuracy(p2, getData(evalu, "unknown")),
  UBCF_Z_C = calcPredictionAccuracy(p3, getData(evalu, "unknown"))
)
error_UCOS
```


 

## Algorithm 2


## Compare 
Compare algorithms.

# Hybrid Recommender System (Juliann)

Create content and collaborative hybrid. Datasets are rich with categorical features of user & item. Reference later for [hybrid model algorithms](https://medium.com/@alfonsollanes/how-do-you-measure-and-evaluate-the-quality-of-recommendation-engines-2e91db5952af). 


Content Process: 

*  Calculate restaurant similarity using cuisine tags/price to build a vector-space representation.
*  Evaluate cosine similarity matrix 
*  Try new machine learning techniques (e.g. Naive Bayes, support vector machines, decision trees, etc) 

Pros:

*  Novelty: Relevant recommendations not based on popularity.

Cons:

*  Over-specialisation
*  May fail diversity test 

Add more later :)

```{r}
library('ordinal')
library('text2vec')
```

```{r}
user_profile
```



# Conclusion

**As part of your textual conclusion, discuss one or more additional experiments that could be performed and/or metrics that could be evaluated only if online evaluation was possible. Also, briefly propose how you would design a reasonable online evaluation environment.**


Also: Compare content algorith outcomes to hybrid approach. 

# References:

[**Building Recommenders**:](https://buildingrecommenders.wordpress.com/2015/11/19/overview-of-recommender-algorithms-part-3/) Overview of Recommender Algorithms
