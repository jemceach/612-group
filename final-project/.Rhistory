# convert to matrix
ui_mat <- matrix_data %>% as.matrix()
# store matrix as realRatingMatrix
ui_mat <- as(ui_mat,"realRatingMatrix")
# view matrix data
matrix_data
# evaluation method with 80% of data for train and 20% for test
set.seed(1000)
evalu <- evaluationScheme(ui_mat, method="split", train=0.8, given=1, goodRating=1, k=10)
# Prep data
train <- getData(evalu, 'train')# Training Dataset
dev_test <- getData(evalu, 'known') # Test data from evaluationScheme of type KNOWN
test <- getData(evalu, 'unknown') # Unknow datset used for RMSE / model evaluation
#install.packages("devtools")
#devtools::install_github("rstudio/sparklyr")
#spark_install(version = "2.4.3")
library(sparklyr)
# configure spark connection
config <- spark_config()
config$spark.executor.memory <- "8G"
config$spark.executor.cores <- 2
config$spark.executor.instances <- 3
config$spark.dynamicAllocation.enabled <- "false"
# initiate connection
sc <- spark_connect(master = "local", config=config, version = "2.4.3")
# unhash to verify version:
# spark_version(sc)
# select data for spark and create spark table
spark_data <- df %>% select(stars, user_id, business_id, name, city, categories)
yelp <- sdf_copy_to(sc, spark_data, "yelp", overwrite = TRUE)
# Transform features
yelp <- yelp %>%
ft_string_indexer(input_col = "user_id", output_col = "user_index") %>%
ft_string_indexer(input_col = "business_id", output_col = "item_index") %>%
select(-user_id, -business_id)%>%
sdf_register("yelp")
# randomly split / train test data
split <- sdf_random_split(yelp, training = 0.8, testing = 0.2, seed=1)
# store training / test sets
train <- sdf_register(split$training, "train")
test <- sdf_register(split$testing, "test")
# tidy train for algoritms that require only user/item inputs
ui_train <- tbl(sc, "train") %>% select(user_index, item_index, stars)
ui_test <- tbl(sc, "test") %>% select(user_index, item_index, stars)
# build model using user/business/ratings
als_fit <- ml_als(ui_train, max_iter = 5, nonnegative = TRUE,
rating_col = "stars",
user_col = "user_index",
item_col = "item_index")
# predict from the model for the training data
als_predict_train <- ml_predict(als_fit, ui_train)
als_predict_test <- ml_predict(als_fit, ui_test)
# store predictions
als_predict_train <- collect(als_predict_train)
als_predict_test <- collect(als_predict_test)
# Remove NaN (result of test/train splits - not data)
als_predict_train <- als_predict_train[!is.na(als_predict_train$prediction), ]
als_predict_test <- als_predict_test[!is.na(als_predict_test$prediction), ]
# Calculate MSE/RMSE/MAE
als_mse_train <- mean((als_predict_train$stars - als_predict_train$prediction)^2)
als_rmse_train <- sqrt(als_mse_train)
als_mae_train <- mean(abs(als_predict_train$stars - als_predict_train$prediction))
als_mse_test <- mean((als_predict_test$stars - als_predict_test$prediction)^2)
als_rmse_test <- sqrt(als_mse_test)
als_mae_test <- mean(abs(als_predict_test$stars - als_predict_test$prediction))
# build model using user/business index, category, and city
rf_fit <- ml_random_forest(
train, # the training partion
response = "stars",
features = colnames(train)[2:4],
impurity = "entropy",
type = "classification",
seed = 1)
# identify important features in model
rf_importance1 <- ml_tree_feature_importance(sc = sc, model = rf_fit)
rf_importance2<- rf_importance1 %>% mutate(importance = round(importance,2)) %>% filter(importance>0)
# percent of terms found important
nrow(rf_importance2)/(nrow(rf_importance1) +nrow(rf_importance2))
# view importance
rf_importance2 %>% kable() %>% kable_styling()
# predict from the model for the training data
rf_predict_train <- ml_predict(rf_fit, train)
rf_predict_train <- collect(rf_predict_train)
# build model using user/business index, category, and city
rf_fit <- ml_random_forest(
train, # the training partion
response = "stars",
features = colnames(train)[2:4],
impurity = "entropy",
type = "classification",
seed = 1)
# identify important features in model
rf_importance1 <- ml_tree_feature_importance(sc = sc, model = rf_fit)
rf_importance2<- rf_importance1 %>% mutate(importance = round(importance,2)) %>% filter(importance>0)
# percent of terms found important
nrow(rf_importance2)/(nrow(rf_importance1) +nrow(rf_importance2))
# view importance
rf_importance2 %>% kable() %>% kable_styling()
# predict from the model for the training data
rf_predict_train <- ml_predict(rf_fit, train)
rf_predict_test <- ml_predict(rf_fit, test)
rf_predict_train <- collect(rf_predict_train)
# predict from the model for the training data
rf_predict_train <- ml_predict(rf_fit, train)
rf_predict_test <- ml_predict(rf_fit, test)
# Remove NaN (result of test/train splits - not data)
rf_predict_train <- rf_predict_train[!is.na(rf_predict_train$prediction), ]
collect(rf_predict_test)
# predict from the model for the training data
rf_predict_train <- ml_predict(rf_fit, train)  %>% collect()
# build model using user/business/ratings
als_fit <- ml_als(ui_train, max_iter = 5, nonnegative = TRUE,
rating_col = "stars",
user_col = "user_index",
item_col = "item_index")
# predict from the model for the training data
als_predict_train <- ml_predict(als_fit, ui_train) %>% collect()
als_predict_test <- ml_predict(als_fit, ui_test) %>% collect()
# Remove NaN (result of test/train splits - not data)
als_predict_train <- als_predict_train[!is.na(als_predict_train$prediction), ]
als_predict_test <- als_predict_test[!is.na(als_predict_test$prediction), ]
# Calculate MSE/RMSE/MAE
als_mse_train <- mean((als_predict_train$stars - als_predict_train$prediction)^2)
als_rmse_train <- sqrt(als_mse_train)
als_mae_train <- mean(abs(als_predict_train$stars - als_predict_train$prediction))
als_mse_test <- mean((als_predict_test$stars - als_predict_test$prediction)^2)
als_rmse_test <- sqrt(als_mse_test)
als_mae_test <- mean(abs(als_predict_test$stars - als_predict_test$prediction))
# build model using user/business index, category, and city
rf_fit <- ml_random_forest(
train, # the training partion
response = "stars",
features = colnames(train)[2:4],
impurity = "entropy",
type = "classification",
seed = 1)
# identify important features in model
rf_importance1 <- ml_tree_feature_importance(sc = sc, model = rf_fit)
rf_importance2<- rf_importance1 %>% mutate(importance = round(importance,2)) %>% filter(importance>0)
# percent of terms found important
nrow(rf_importance2)/(nrow(rf_importance1) +nrow(rf_importance2))
# view importance
rf_importance2 %>% kable() %>% kable_styling()
# predict from the model for the training data
rf_predict_train <- ml_predict(rf_fit, train)  %>% collect()
# build model using user/business index, category, and city
rf_fit <- ml_random_forest(
train, # the training partion
response = "stars",
features = colnames(train)[2:4],
impurity = "entropy",
type = "classification",
seed = 1)
# identify important features in model
rf_importance1 <- ml_tree_feature_importance(sc = sc, model = rf_fit)
rf_importance2<- rf_importance1 %>% mutate(importance = round(importance,2)) %>% filter(importance>0)
# percent of terms found important
nrow(rf_importance2)/nrow(rf_importance1)
# view importance
rf_importance2 %>% kable() %>% kable_styling()
# build model using user/business index, category, and city
rf_fit <- ml_random_forest(
train, # the training partion
response = "stars",
features = colnames(train)[2:4],
impurity = "entropy",
type = "classification",
seed = 1)
# build model using user/business index, category, and city
rf_fit <- ml_random_forest(
train, # the training partion
response = "stars",
features = colnames(train)[2:4],
impurity = "entropy",
type = "classification",
seed = 1)
# identify important features in model
rf_importance1 <- ml_tree_feature_importance(sc = sc, model = rf_fit)
rf_importance2<- rf_importance1 %>% mutate(importance = round(importance,2)) %>% filter(importance>0)
# percent of terms found important
nrow(rf_importance2)/nrow(rf_importance1)
# view importance
rf_importance2 %>% kable() %>% kable_styling()
# calculate accuracy
rf_eval_train <- rf_predict_train %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
rf_eval_test <- rf_eval_test %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
# calculate accuracy
rf_eval_train <- rf_predict_train %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
rf_eval_test <- rf_predict_test %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
# calculate accuracy
rf_eval_train <- rf_predict_train %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
rf_eval_test <- rf_predict_test %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
# make predictions
rf_predict_train <- ml_predict(rf_fit, train)  %>% collect()
# make predictions
rf_predict_train <- ml_predict(rf_fit, train)
rf_predict_test <- ml_predict(rf_fit, test)
# calculate accuracy
rf_eval_train <- rf_predict_train %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
rf_eval_test <- rf_predict_test %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
# make predictions
rf_predict_train <- ml_predict(rf_fit, train)
rf_predict_test <- ml_predict(rf_fit, test)
# calculate accuracy
rf_eval_train <- rf_predict_train %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
##UNABLE TO GET TEST ACCURACY
#rf_eval_test <- rf_predict_test %>%
#  ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
rf_eval_train
# View metrics
als_train_metrics<- cbind(als_rmse_train,als_mse_train, als_mae_train)
## data processing packages
library(dplyr)
##formatting packages
library(knitr); library(kableExtra); library(default)
##visualization packages
library(ggplot2)
##recommender packages
library(recommenderlab); library(Metrics); library(lsa); library(diveRsity)
## Sparklyr
#install.packages("devtools")
#devtools::install_github("rstudio/sparklyr")
#spark_install(version = "2.4.3")
library(sparklyr)
##preprocessing data
suppressWarnings(source("preprocessing.R"))
## data processing packages
library(dplyr)
##formatting packages
library(knitr); library(kableExtra); library(default)
##visualization packages
library(ggplot2)
##recommender packages
library(recommenderlab); library(Metrics); library(lsa); library(diveRsity)
## Sparklyr
#install.packages("devtools")
#devtools::install_github("rstudio/sparklyr")
#spark_install(version = "2.4.3")
library(sparklyr)
##preprocessing data
suppressWarnings(source("preprocessing.R"))
# global options
## knit sizing
options(max.print="100"); opts_knit$set(width=75)
## augment chunk output
opts_chunk$set(echo=T,cache=F, tidy=T,comment=F,message=T,warning=T) #change message/warning to F upon completion
## set table style for consistency
default(kable) <- list(format="html")
default(kable_styling)  <- list(bootstrap_options = "hover",full_width=T, font_size=10)
default(scroll_box) <- list(width = "100%")
# set row names to userid
rownames(matrix_data)<-matrix_data$userID
# spread data from long to wide format
matrix_data <- df %>% select(userID, itemID, stars) %>% spread(itemID, stars)
# set row names to userid
rownames(matrix_data)<-matrix_data$userID
# remove userid from columns
matrix_data <-matrix_data %>% select(-userID)
# convert to matrix
ui_mat <- matrix_data %>% as.matrix()
# store matrix as realRatingMatrix
ui_mat <- as(ui_mat,"realRatingMatrix")
# evaluation method with 80% of data for train and 20% for test
set.seed(1000)
evalu <- evaluationScheme(ui_mat, method="split", train=0.8, given=1, goodRating=1, k=10)
# prep data
train <- getData(evalu, 'train')# Training Dataset
dev_test <- getData(evalu, 'known') # Test data from evaluationScheme of type KNOWN
test <- getData(evalu, 'unknown') # Unknow datset used for RMSE / model evaluation
# configure spark connection
config <- spark_config()
config$spark.executor.memory <- "8G"
config$spark.executor.cores <- 2
config$spark.executor.instances <- 3
config$spark.dynamicAllocation.enabled <- "false"
# initiate connection
sc <- spark_connect(master = "local", config=config, version = "2.4.3")
# unhash to verify version:
# spark_version(sc)
# select data for spark and create spark table
spark_train <- as(train,"data.frame")
spark_test<- as(test,"data.frame")
spark_train <- sdf_copy_to(sc, spark_train, "spark_train", overwrite = TRUE)
spark_test <- sdf_copy_to(sc, spark_test, "spark_test", overwrite = TRUE)
# Transform features
spark_train <- spark_train %>%
ft_string_indexer(input_col = "user", output_col = "user_index") %>%
ft_string_indexer(input_col = "item", output_col = "item_index") %>%
sdf_register("spark_train")
spark_test <- spark_test %>%
ft_string_indexer(input_col = "user", output_col = "user_index") %>%
ft_string_indexer(input_col = "item", output_col = "item_index") %>%
sdf_register("spark_test")
# build model using user/business/ratings
als_fit <- ml_als(spark_train, max_iter = 5, nonnegative = TRUE,
rating_col = "rating",
user_col = "user_index",
item_col = "item_index")
# predict from the model for the training data
als_predict_train <- ml_predict(als_fit, spark_train) %>% collect()
als_predict_test <- ml_predict(als_fit, spark_test) %>% collect()
# Remove NaN (result of test/train splits - not data)
als_predict_train <- als_predict_train[!is.na(als_predict_train$prediction), ]
als_predict_test <- als_predict_test[!is.na(als_predict_test$prediction), ]
# View results
als_predict_test %>% head %>% kable() %>% kable_styling()
# Calculate RMSE/MSE/MAE
als_mse_train <- mean((als_predict_train$stars - als_predict_train$prediction)^2)
als_rmse_train <- sqrt(als_mse_train)
als_mae_train <- mean(abs(als_predict_train$stars - als_predict_train$prediction))
als_mse_test <- mean((als_predict_test$stars - als_predict_test$prediction)^2)
als_rmse_test <- sqrt(als_mse_test)
als_mae_test <- mean(abs(als_predict_test$stars - als_predict_test$prediction))
# Calculate RMSE/MSE/MAE
als_mse_train <- mean((als_predict_train$rating - als_predict_train$prediction)^2)
als_rmse_train <- sqrt(als_mse_train)
als_mae_train <- mean(abs(als_predict_train$rating - als_predict_train$prediction))
als_mse_test <- mean((als_predict_test$rating - als_predict_test$prediction)^2)
als_rmse_test <- sqrt(als_mse_test)
als_mae_test <- mean(abs(als_predict_test$rating - als_predict_test$prediction))
# View metrics
als_train_metrics<- cbind(als_rmse_train,als_mse_train, als_mae_train)
als_test_metrics<-cbind(als_rmse_test, als_mse_test, als_mae_test)
als_metrics <- as.data.frame(rbind(als_train_metrics,als_test_metrics), row.names = c("ALS_train, ALS_test"))
als_metrics %>% rename(rmse = als_rmse_train, mse = als_mse_train, mae=als_mae_train)
## data processing packages
library(dplyr)
##formatting packages
library(knitr); library(kableExtra); library(default)
##visualization packages
library(ggplot2)
##recommender packages
library(recommenderlab); library(Metrics); library(lsa); library(diveRsity)
## Sparklyr
#install.packages("devtools")
#devtools::install_github("rstudio/sparklyr")
#spark_install(version = "2.4.3")
library(sparklyr)
##preprocessing data
suppressWarnings(source("preprocessing.R"))
# global options
## knit sizing
options(max.print="100"); opts_knit$set(width=75)
## augment chunk output
opts_chunk$set(echo=T,cache=F, tidy=T,comment=F,message=T,warning=T) #change message/warning to F upon completion
## set table style for consistency
default(kable) <- list(format="html")
default(kable_styling)  <- list(bootstrap_options = "hover",full_width=T, font_size=10)
default(scroll_box) <- list(width = "100%")
#preview business
business %>% head() %>% kable(caption="Preview Business Data") %>% kable_styling()
#preview reviews
review %>% select() %>% head(1) %>% kable(caption="Preview Review Data (without Review Text)") %>% kable_styling()
#preview users
user %>% head() %>% kable(caption="Preview User Data") %>% kable_styling()
df %>% select(-text,-business_id, -user_id,-review_id) %>% head() %>% kable(caption="Preview main dataframe") %>% kable_styling()
# spread data from long to wide format
matrix_data <- df %>% select(userID, itemID, stars) %>% spread(itemID, stars)
# set row names to userid
rownames(matrix_data)<-matrix_data$userID
# remove userid from columns
matrix_data <-matrix_data %>% select(-userID)
# convert to matrix
ui_mat <- matrix_data %>% as.matrix()
# store matrix as realRatingMatrix
ui_mat <- as(ui_mat,"realRatingMatrix")
# view matrix data
matrix_data %>% head()
# evaluation method with 80% of data for train and 20% for test
set.seed(0)
evalu <- evaluationScheme(ui_mat, method="split", train=0.8, given=1, goodRating=1, k=10)
# prep data
train <- getData(evalu, 'train')# Training Dataset
dev_test <- getData(evalu, 'known') # Test data from evaluationScheme of type KNOWN
test <- getData(evalu, 'unknown') # Unknow datset used for RMSE / model evaluation
UB <- Recommender(getData(evalu, "train"), "UBCF",
param=list(normalize = "Z-score",method="Cosine"))
p <- predict(UB, getData(evalu, "known"), type="ratings")
p@data@x[p@data@x[] < 1] <- 1
p@data@x[p@data@x[] > 5] <- 5
calcPredictionAccuracy(p, getData(evalu, "unknown"))
IB <- Recommender(getData(evalu, "train"), "IBCF",
param=list(normalize = "Z-score",method="Cosine"))
p1 <- predict(IB, getData(evalu, "known"), type="ratings")
p1@data@x[p1@data@x[] < 1] <- 1
p1@data@x[p1@data@x[] > 5] <- 5
calcPredictionAccuracy(p1, getData(evalu, "unknown"))
# configure spark connection
config <- spark_config()
config$spark.executor.memory <- "8G"
config$spark.executor.cores <- 2
config$spark.executor.instances <- 3
config$spark.dynamicAllocation.enabled <- "false"
# initiate connection
sc <- spark_connect(master = "local", config=config, version = "2.4.3")
# unhash to verify version:
# spark_version(sc)
# select data for spark and create spark table
spark_train <- as(train,"data.frame")
spark_test<- as(test,"data.frame")
spark_train <- sdf_copy_to(sc, spark_train, "spark_train", overwrite = TRUE)
spark_test <- sdf_copy_to(sc, spark_test, "spark_test", overwrite = TRUE)
# Transform features
spark_train <- spark_train %>%
ft_string_indexer(input_col = "user", output_col = "user_index") %>%
ft_string_indexer(input_col = "item", output_col = "item_index") %>%
sdf_register("spark_train")
spark_test <- spark_test %>%
ft_string_indexer(input_col = "user", output_col = "user_index") %>%
ft_string_indexer(input_col = "item", output_col = "item_index") %>%
sdf_register("spark_test")
# build model using user/business/ratings
als_fit <- ml_als(spark_train, max_iter = 5, nonnegative = TRUE,
rating_col = "rating",
user_col = "user_index",
item_col = "item_index")
# predict from the model for the training data
als_predict_train <- ml_predict(als_fit, spark_train) %>% collect()
als_predict_test <- ml_predict(als_fit, spark_test) %>% collect()
# Remove NaN (result of test/train splits - not data)
als_predict_train <- als_predict_train[!is.na(als_predict_train$prediction), ]
als_predict_test <- als_predict_test[!is.na(als_predict_test$prediction), ]
# View results
als_predict_test %>% head %>% kable() %>% kable_styling()
# Calculate RMSE/MSE/MAE
als_mse_train <- mean((als_predict_train$rating - als_predict_train$prediction)^2)
als_rmse_train <- sqrt(als_mse_train)
als_mae_train <- mean(abs(als_predict_train$rating - als_predict_train$prediction))
als_mse_test <- mean((als_predict_test$rating - als_predict_test$prediction)^2)
als_rmse_test <- sqrt(als_mse_test)
als_mae_test <- mean(abs(als_predict_test$rating - als_predict_test$prediction))
# View metrics
als_train_metrics<- cbind(als_rmse_train,als_mse_train, als_mae_train)
als_test_metrics<-cbind(als_rmse_test, als_mse_test, als_mae_test)
als_metrics <- as.data.frame(rbind(als_train_metrics,als_test_metrics), row.names = c("ALS_train, ALS_test"))
als_metrics %>% rename(rmse = als_rmse_train, mse = als_mse_train, mae=als_mae_train)
# disconnect
spark_disconnect(sc)
# configure spark connection
config <- spark_config()
config$spark.executor.memory <- "8G"
config$spark.executor.cores <- 2
config$spark.executor.instances <- 3
config$spark.dynamicAllocation.enabled <- "false"
# initiate connection
sc <- spark_connect(master = "local", config=config, version = "2.4.3")
# unhash to verify version:
# spark_version(sc)
# select data for spark and create spark table
spark_train <- as(train,"data.frame")
spark_test<- as(test,"data.frame")
spark_train <- sdf_copy_to(sc, spark_train, "spark_train", overwrite = TRUE)
spark_test <- sdf_copy_to(sc, spark_test, "spark_test", overwrite = TRUE)
# Transform features
spark_train <- spark_train %>%
ft_string_indexer(input_col = "user", output_col = "user_index") %>%
ft_string_indexer(input_col = "item", output_col = "item_index") %>%
sdf_register("spark_train")
spark_test <- spark_test %>%
ft_string_indexer(input_col = "user", output_col = "user_index") %>%
ft_string_indexer(input_col = "item", output_col = "item_index") %>%
sdf_register("spark_test")
# build model using user/business/ratings
als_fit <- ml_als(spark_train, max_iter = 5, nonnegative = TRUE,
rating_col = "rating",
user_col = "user_index",
item_col = "item_index")
# predict from the model for the training data
als_predict_train <- ml_predict(als_fit, spark_train) %>% collect()
als_predict_test <- ml_predict(als_fit, spark_test) %>% collect()
# Remove NaN (result of test/train splits - not data)
als_predict_train <- als_predict_train[!is.na(als_predict_train$prediction), ]
als_predict_test <- als_predict_test[!is.na(als_predict_test$prediction), ]
# View results
als_predict_test %>% head %>% kable() %>% kable_styling()
ml_recommend(als_fit)
ml_recommend(als_fit, type="items",n=5)
ml_recommend(als_fit, type="users", n=5)
?ml_recommend
als_item_recommend<- ml_recommend(als_fit, type="items",n=5)
als_user_recommend<-ml_recommend(als_fit, type="users", n=5)
als_item_recommend %>% filter(user_index==50)
als_user_recommend %>% filter(user_index==50)
als_user_recommend %>% filter(user_index==10)
als_user_recommend %>% filter(user_index==10)
als_user_recommend %>% filter(user_index==12)
als_user_recommend %
als_user_recommend
als_user_recommend$recommendations
als_user_recommend
als_user_recommend<-ml_recommend(als_fit, type="users", n=10)
als_user_recommend %>% head()
als_user_recommend %>% head(10)
als_user_recommend %>% head(10)
als_user_recommend<-ml_recommend(als_fit, type="users", n=10) %>% collect()
als_user_recommend<-ml_recommend(als_fit, type="users", n=10)
als_user_recommend<-ml_recommend(als_fit, type="users", n=10)
als_user_recommend %>% head(10) %>% collect()
t<-als_user_recommend %>% head(10) %>% collect()
t
t<-als_user_recommend %>% head(10) %>% collect()
t$recommendations
als_user_recommend %>% head(10) %>% collect() %>% select(-recommendations)
