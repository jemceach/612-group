business <- business %>%
filter(business_id %in% review$business_id)
## Recalculate aggregate votes/average stars/review counts.
user <- user %>% select(user_id, name) %>%
inner_join(review, by="user_id") %>%
select(-date, -review_id)%>%
group_by(user_id,name) %>%
rename(user_name = name) %>%
summarize(review_count = n(),
avg_votes_funny = round(mean(votes.funny, na.rm = TRUE)),
avg_votes_useful = round(mean(votes.useful, na.rm = TRUE)),
avg_votes_cool = round(mean(votes.cool, na.rm = TRUE)),
avg_user_stars = round(mean(stars),1)) %>%
ungroup()
# MERGE DATAFRAME
## Created our main dataframe business and review dataframes.
## Set `Business_ID` as unique keys.
df <- business %>%
inner_join(review, by="business_id")
#######################################
#--------Data612 Final Project--------#
#--Data Processing & Transformations--#
#######################################
# R DEPENDENCIES
library(dplyr)
library(tidyr)
library(jsonlite)
library(stringr)
setwd("~/GitHub/612-group/final-project")
# DATA AQUISITION
## Business Data
business<-stream_in(file("data/yelp_training_set_business.json"),verbose = F)
## User Data
user <-stream_in(file("data/yelp_training_set_user.json"),verbose = F)
## Review  Data
review <-stream_in(file("data/yelp_training_set_review.json"),verbose = F)
# DATA TRANSFORMATIONS
#------BUSINESS-------#
#Selected only open businesses.
#Removed out-of-state businesses.
#Deleted unused columns.
#Filtered food/beverage categories.
#Factored categories.
#---------------------#
## Subset data
business <- business %>%
filter(open == "TRUE", state=="AZ") %>%
select(-open, -neighborhoods, -full_address, -review_count, -type, -stars) %>%
mutate(categories = sapply(categories, toString))
## Create category filter
filter <- 'Argentine| Burmese| Cambodian| Cocktail Bars|Laotian|Lebanese|Live/Raw Food|Russian|African|Champagne Bars|Kosher|Modern European|Scandinavian|Taiwanese|Tapas/Small Plates|Afghan|Brazilian|Food Trucks|Shaved Ice|Wineries|Dim Sum|Ethiopian|Fondue|Hookah Bars|Persian/Iranian|Peruvian| Polish| Seafood Markets| Tapas Bars|Halal|British| Cheese Shops|German|Spanish|Cheesesteaks|Cuban|Do-It-Yourself Food|Gastropubs|Salad|Creperies|Soup|Chocolatiers & Shops|Filipino|Food Stands|Fruits & Veggies|Meat Shops|Mongolian|Soul Food|Comfort Food| Irish|Fish & Chips|Cajun/Creole|Caribbean|Pakistani|Southern|Candy Stores|Vegan|Latin American|Breweries|French|Gay Bars|Korean|Gluten-Free|Hawaiian|Farmers Market|Vegetarian|Middle Eastern|Ethnic Food|Indian|Pubs|Chicken Wings|Dive Bars| Juice Bars & Smoothies|Vietnamese|Cafes|Wine Bars|Bagels|Diners|Hot Dogs|Tex-Mex|Donuts|Greek|Thai| Desserts|Mediterranean|Beer| Wine & Spirits|Seafood|Sushi Bars| Lounges|Steakhouses|Buffets|Japanese|Sports Bars|Delis|Bakeries|Specialty Food|Breakfast & Brunch|Ice Cream & Frozen Yogurt|Burgers|Italian| Chinese|Coffee & Tea|American (New)|Sandwiches|Fast Food|Pizza|American (Traditional)|Bars|Mexican|Food| Restaurants'
## Filter businesses using filter &
business <- business %>%
filter(str_detect(categories, filter)) %>%
mutate(categories = as.factor(categories))
#-------REVIEW--------#
#Used business subset to filter out-of-scope reviews.
#Deleted unused columns.
#Convert ratings dataframe (funny/useful/cool) into singular columns.
#---------------------#
## filter data in business
review <- review %>%
filter(business_id %in% business$business_id) %>%
select(-type)
## remove factor from user_id
review$user_id <- as.character(review$user_id)
review$business_id <- as.character(review$business_id)
#--------USER---------#
#Used business subset to filter out-of-scope reviews.
#Deleted unused columns.
#Took random sample of 10k users.
#Filter review/business from user subset.
#Dropped aggregate data and recalculated avgs based on subset.
#---------------------#
## filter data in business
user <- user %>%
filter(user_id %in% review$user_id) %>%
select(-type)
## randomly sample 10k
set.seed(50)
user<-sample_n(user, 10000)
## filter review data from user subset (121329 reviews were reomved)
review <- review %>%
filter(user_id %in% user$user_id)
## assemble ratings data (funny/useful/cool) into singular columns.
review <- do.call(data.frame, review)
## assemble ratings data (funny/useful/cool) into singular columns.
user <- do.call(data.frame, user)
## filter business data from new review/user subset (496 businesses were removed)
business <- business %>%
filter(business_id %in% review$business_id)
## Recalculate aggregate votes/average stars/review counts.
user <- user %>% select(user_id, name) %>%
inner_join(review, by="user_id") %>%
select(-date, -review_id)%>%
group_by(user_id,name) %>%
rename(user_name = name) %>%
summarize(review_count = n(),
avg_votes_funny = round(mean(votes.funny, na.rm = TRUE)),
avg_votes_useful = round(mean(votes.useful, na.rm = TRUE)),
avg_votes_cool = round(mean(votes.cool, na.rm = TRUE)),
avg_user_stars = round(mean(stars),1)) %>%
ungroup()
# MERGE DATAFRAME
## Created our main dataframe business and review dataframes.
## Set `Business_ID` as unique keys.
## Set numeric user/item keys for spark.
df <- business %>%
inner_join(review, by="business_id") %>%
transform(userID=match(user_id, unique(userID)))%>%
transform(itemID=match(business_id, unique(business_id)))
#######################################
#--------Data612 Final Project--------#
#--Data Processing & Transformations--#
#######################################
# R DEPENDENCIES
library(dplyr)
library(tidyr)
library(jsonlite)
library(stringr)
setwd("~/GitHub/612-group/final-project")
# DATA AQUISITION
## Business Data
business<-stream_in(file("data/yelp_training_set_business.json"),verbose = F)
## User Data
user <-stream_in(file("data/yelp_training_set_user.json"),verbose = F)
## Review  Data
review <-stream_in(file("data/yelp_training_set_review.json"),verbose = F)
# DATA TRANSFORMATIONS
#------BUSINESS-------#
#Selected only open businesses.
#Removed out-of-state businesses.
#Deleted unused columns.
#Filtered food/beverage categories.
#Factored categories.
#---------------------#
## Subset data
business <- business %>%
filter(open == "TRUE", state=="AZ") %>%
select(-open, -neighborhoods, -full_address, -review_count, -type, -stars) %>%
mutate(categories = sapply(categories, toString))
## Create category filter
filter <- 'Argentine| Burmese| Cambodian| Cocktail Bars|Laotian|Lebanese|Live/Raw Food|Russian|African|Champagne Bars|Kosher|Modern European|Scandinavian|Taiwanese|Tapas/Small Plates|Afghan|Brazilian|Food Trucks|Shaved Ice|Wineries|Dim Sum|Ethiopian|Fondue|Hookah Bars|Persian/Iranian|Peruvian| Polish| Seafood Markets| Tapas Bars|Halal|British| Cheese Shops|German|Spanish|Cheesesteaks|Cuban|Do-It-Yourself Food|Gastropubs|Salad|Creperies|Soup|Chocolatiers & Shops|Filipino|Food Stands|Fruits & Veggies|Meat Shops|Mongolian|Soul Food|Comfort Food| Irish|Fish & Chips|Cajun/Creole|Caribbean|Pakistani|Southern|Candy Stores|Vegan|Latin American|Breweries|French|Gay Bars|Korean|Gluten-Free|Hawaiian|Farmers Market|Vegetarian|Middle Eastern|Ethnic Food|Indian|Pubs|Chicken Wings|Dive Bars| Juice Bars & Smoothies|Vietnamese|Cafes|Wine Bars|Bagels|Diners|Hot Dogs|Tex-Mex|Donuts|Greek|Thai| Desserts|Mediterranean|Beer| Wine & Spirits|Seafood|Sushi Bars| Lounges|Steakhouses|Buffets|Japanese|Sports Bars|Delis|Bakeries|Specialty Food|Breakfast & Brunch|Ice Cream & Frozen Yogurt|Burgers|Italian| Chinese|Coffee & Tea|American (New)|Sandwiches|Fast Food|Pizza|American (Traditional)|Bars|Mexican|Food| Restaurants'
## Filter businesses using filter &
business <- business %>%
filter(str_detect(categories, filter)) %>%
mutate(categories = as.factor(categories))
#-------REVIEW--------#
#Used business subset to filter out-of-scope reviews.
#Deleted unused columns.
#Convert ratings dataframe (funny/useful/cool) into singular columns.
#---------------------#
## filter data in business
review <- review %>%
filter(business_id %in% business$business_id) %>%
select(-type)
## remove factor from user_id
review$user_id <- as.character(review$user_id)
review$business_id <- as.character(review$business_id)
#--------USER---------#
#Used business subset to filter out-of-scope reviews.
#Deleted unused columns.
#Took random sample of 10k users.
#Filter review/business from user subset.
#Dropped aggregate data and recalculated avgs based on subset.
#---------------------#
## filter data in business
user <- user %>%
filter(user_id %in% review$user_id) %>%
select(-type)
## randomly sample 10k
set.seed(50)
user<-sample_n(user, 10000)
## filter review data from user subset (121329 reviews were reomved)
review <- review %>%
filter(user_id %in% user$user_id)
## assemble ratings data (funny/useful/cool) into singular columns.
review <- do.call(data.frame, review)
## assemble ratings data (funny/useful/cool) into singular columns.
user <- do.call(data.frame, user)
## filter business data from new review/user subset (496 businesses were removed)
business <- business %>%
filter(business_id %in% review$business_id)
## Recalculate aggregate votes/average stars/review counts.
user <- user %>% select(user_id, name) %>%
inner_join(review, by="user_id") %>%
select(-date, -review_id)%>%
group_by(user_id,name) %>%
rename(user_name = name) %>%
summarize(review_count = n(),
avg_votes_funny = round(mean(votes.funny, na.rm = TRUE)),
avg_votes_useful = round(mean(votes.useful, na.rm = TRUE)),
avg_votes_cool = round(mean(votes.cool, na.rm = TRUE)),
avg_user_stars = round(mean(stars),1)) %>%
ungroup()
# MERGE DATAFRAME
## Created our main dataframe business and review dataframes.
## Set `Business_ID` as unique keys.
## Set numeric user/item keys for spark.
df <- business %>%
inner_join(review, by="business_id") %>%
transform(userID=match(user_id, unique(user_id)))%>%
transform(itemID=match(business_id, unique(business_id)))
#######################################
#--------Data612 Final Project--------#
#--Data Processing & Transformations--#
#######################################
# R DEPENDENCIES
library(dplyr)
library(tidyr)
library(jsonlite)
library(stringr)
setwd("~/GitHub/612-group/final-project")
# DATA AQUISITION
## Business Data
business<-stream_in(file("data/yelp_training_set_business.json"),verbose = F)
## User Data
user <-stream_in(file("data/yelp_training_set_user.json"),verbose = F)
## Review  Data
review <-stream_in(file("data/yelp_training_set_review.json"),verbose = F)
# DATA TRANSFORMATIONS
#------BUSINESS-------#
#Selected only open businesses.
#Removed out-of-state businesses.
#Deleted unused columns.
#Filtered food/beverage categories.
#Factored categories.
#---------------------#
## Subset data
business <- business %>%
filter(open == "TRUE", state=="AZ") %>%
select(-open, -neighborhoods, -full_address, -review_count, -type, -stars) %>%
mutate(categories = sapply(categories, toString))
## Create category filter
filter <- 'Argentine| Burmese| Cambodian| Cocktail Bars|Laotian|Lebanese|Live/Raw Food|Russian|African|Champagne Bars|Kosher|Modern European|Scandinavian|Taiwanese|Tapas/Small Plates|Afghan|Brazilian|Food Trucks|Shaved Ice|Wineries|Dim Sum|Ethiopian|Fondue|Hookah Bars|Persian/Iranian|Peruvian| Polish| Seafood Markets| Tapas Bars|Halal|British| Cheese Shops|German|Spanish|Cheesesteaks|Cuban|Do-It-Yourself Food|Gastropubs|Salad|Creperies|Soup|Chocolatiers & Shops|Filipino|Food Stands|Fruits & Veggies|Meat Shops|Mongolian|Soul Food|Comfort Food| Irish|Fish & Chips|Cajun/Creole|Caribbean|Pakistani|Southern|Candy Stores|Vegan|Latin American|Breweries|French|Gay Bars|Korean|Gluten-Free|Hawaiian|Farmers Market|Vegetarian|Middle Eastern|Ethnic Food|Indian|Pubs|Chicken Wings|Dive Bars| Juice Bars & Smoothies|Vietnamese|Cafes|Wine Bars|Bagels|Diners|Hot Dogs|Tex-Mex|Donuts|Greek|Thai| Desserts|Mediterranean|Beer| Wine & Spirits|Seafood|Sushi Bars| Lounges|Steakhouses|Buffets|Japanese|Sports Bars|Delis|Bakeries|Specialty Food|Breakfast & Brunch|Ice Cream & Frozen Yogurt|Burgers|Italian| Chinese|Coffee & Tea|American (New)|Sandwiches|Fast Food|Pizza|American (Traditional)|Bars|Mexican|Food| Restaurants'
## Filter businesses using filter &
business <- business %>%
filter(str_detect(categories, filter)) %>%
mutate(categories = as.factor(categories))
#-------REVIEW--------#
#Used business subset to filter out-of-scope reviews.
#Deleted unused columns.
#Convert ratings dataframe (funny/useful/cool) into singular columns.
#---------------------#
## filter data in business
review <- review %>%
filter(business_id %in% business$business_id) %>%
select(-type)
## remove factor from user_id
review$user_id <- as.character(review$user_id)
review$business_id <- as.character(review$business_id)
#--------USER---------#
#Used business subset to filter out-of-scope reviews.
#Deleted unused columns.
#Took random sample of 10k users.
#Filter review/business from user subset.
#Dropped aggregate data and recalculated avgs based on subset.
#---------------------#
## filter data in business
user <- user %>%
filter(user_id %in% review$user_id) %>%
select(-type) %>%
mutate(user_id = as.character(user_id))
## randomly sample 10k
set.seed(50)
user<-sample_n(user, 10000)
## filter review data from user subset (121329 reviews were reomved)
review <- review %>%
filter(user_id %in% user$user_id)
## assemble ratings data (funny/useful/cool) into singular columns.
review <- do.call(data.frame, review)
## assemble ratings data (funny/useful/cool) into singular columns.
user <- do.call(data.frame, user)
## filter business data from new review/user subset (496 businesses were removed)
business <- business %>%
filter(business_id %in% review$business_id)
## Recalculate aggregate votes/average stars/review counts.
user <- user %>% select(user_id, name) %>%
inner_join(review, by="user_id") %>%
select(-date, -review_id)%>%
group_by(user_id,name) %>%
rename(user_name = name) %>%
summarize(review_count = n(),
avg_votes_funny = round(mean(votes.funny, na.rm = TRUE)),
avg_votes_useful = round(mean(votes.useful, na.rm = TRUE)),
avg_votes_cool = round(mean(votes.cool, na.rm = TRUE)),
avg_user_stars = round(mean(stars),1)) %>%
ungroup()
# MERGE DATAFRAME
## Created our main dataframe business and review dataframes.
## Set `Business_ID` as unique keys.
## Set numeric user/item keys for spark.
df <- business %>%
inner_join(review, by="business_id") %>%
transform(userID=match(user_id, unique(user_id)))%>%
transform(itemID=match(business_id, unique(business_id)))
# DATA TRANSFORMATIONS
#######################################
#--------Data612 Final Project--------#
#--Data Processing & Transformations--#
#######################################
# R DEPENDENCIES
library(dplyr)
library(tidyr)
library(jsonlite)
library(stringr)
setwd("~/GitHub/612-group/final-project")
# DATA AQUISITION
## Business Data
business<-stream_in(file("data/yelp_training_set_business.json"),verbose = F)
## User Data
user <-stream_in(file("data/yelp_training_set_user.json"),verbose = F)
## Review  Data
review <-stream_in(file("data/yelp_training_set_review.json"),verbose = F)
# DATA TRANSFORMATIONS
business <- business %>%
filter(open == "TRUE", state=="AZ") %>%
select(-open, -neighborhoods, -full_address, -review_count, -type, -stars) %>%
mutate(categories = sapply(categories, toString))
## Create category filter
filter <- 'Argentine| Burmese| Cambodian| Cocktail Bars|Laotian|Lebanese|Live/Raw Food|Russian|African|Champagne Bars|Kosher|Modern European|Scandinavian|Taiwanese|Tapas/Small Plates|Afghan|Brazilian|Food Trucks|Shaved Ice|Wineries|Dim Sum|Ethiopian|Fondue|Hookah Bars|Persian/Iranian|Peruvian| Polish| Seafood Markets| Tapas Bars|Halal|British| Cheese Shops|German|Spanish|Cheesesteaks|Cuban|Do-It-Yourself Food|Gastropubs|Salad|Creperies|Soup|Chocolatiers & Shops|Filipino|Food Stands|Fruits & Veggies|Meat Shops|Mongolian|Soul Food|Comfort Food| Irish|Fish & Chips|Cajun/Creole|Caribbean|Pakistani|Southern|Candy Stores|Vegan|Latin American|Breweries|French|Gay Bars|Korean|Gluten-Free|Hawaiian|Farmers Market|Vegetarian|Middle Eastern|Ethnic Food|Indian|Pubs|Chicken Wings|Dive Bars| Juice Bars & Smoothies|Vietnamese|Cafes|Wine Bars|Bagels|Diners|Hot Dogs|Tex-Mex|Donuts|Greek|Thai| Desserts|Mediterranean|Beer| Wine & Spirits|Seafood|Sushi Bars| Lounges|Steakhouses|Buffets|Japanese|Sports Bars|Delis|Bakeries|Specialty Food|Breakfast & Brunch|Ice Cream & Frozen Yogurt|Burgers|Italian| Chinese|Coffee & Tea|American (New)|Sandwiches|Fast Food|Pizza|American (Traditional)|Bars|Mexican|Food| Restaurants'
## Filter businesses using filter
business <- business %>%
filter(str_detect(categories, filter)) %>%
mutate(categories = as.factor(categories))
## filter data in business
review <- review %>%
filter(business_id %in% business$business_id) %>%
select(-type)
## filter data in business
user <- user %>%
filter(user_id %in% review$user_id) %>%
select(-type) %>%
mutate(user_id = as.character(user_id))
## randomly sample 10k
set.seed(50)
user<-sample_n(user, 10000)
## filter review data from user subset (121329 reviews were reomved)
review <- review %>%
filter(user_id %in% user$user_id)
## assemble ratings data (funny/useful/cool) into singular columns.
review <- do.call(data.frame, review)
## assemble ratings data (funny/useful/cool) into singular columns.
user <- do.call(data.frame, user)
## change factors to character
user$user_id <- as.character(user$user_id)
review$user_id<-as.character(review$user_id)
review$business_id<-as.character(review$business_id)
## filter business data from new review/user subset (496 businesses were removed)
business <- business %>%
filter(business_id %in% review$business_id)
df <- business %>%
inner_join(review, by="business_id") %>%
transform(userID=match(user_id, unique(user_id)))%>%
transform(itemID=match(business_id, unique(business_id)))
## data processing packages
library(dplyr)
##formatting packages
library(knitr); library(kableExtra); library(default)
##visualization packages
library(ggplot2)
##recommender packages
library(recommenderlab); library(Metrics); library(lsa); library(diveRsity)
##preprocessing data
try(setwd("~/GitHub/612-group/final-project"))
suppressWarnings(source("preprocessing.R"))
## data processing packages
library(dplyr)
##formatting packages
library(knitr); library(kableExtra); library(default)
##visualization packages
library(ggplot2)
##recommender packages
library(recommenderlab); library(Metrics); library(lsa); library(diveRsity)
##preprocessing data
try(setwd("~/GitHub/612-group/final-project"))
suppressWarnings(source("preprocessing.R"))
## data processing packages
library(dplyr)
##formatting packages
library(knitr); library(kableExtra); library(default)
##visualization packages
library(ggplot2)
##recommender packages
library(recommenderlab); library(Metrics); library(lsa); library(diveRsity)
##preprocessing data
try(setwd("~/GitHub/612-group/final-project"))
suppressWarnings(source("preprocessing.R"))
# global options
## knit sizing
options(max.print="100"); opts_knit$set(width=75)
## augment chunk output
opts_chunk$set(echo=T,cache=F, tidy=T,comment=F,message=T,warning=T) #change message/warning to F upon completion
## set table style for consistency
default(kable) <- list(format="html")
default(kable_styling)  <- list(bootstrap_options = "hover",full_width=T, font_size=10)
default(scroll_box) <- list(width = "100%")
## data processing packages
library(dplyr)
##formatting packages
library(knitr); library(kableExtra); library(default)
##visualization packages
library(ggplot2)
##recommender packages
library(recommenderlab); library(Metrics); library(lsa); library(diveRsity)
##preprocessing data
try(setwd("~/GitHub/612-group/final-project"))
suppressWarnings(source("preprocessing.R"))
# global options
## knit sizing
options(max.print="100"); opts_knit$set(width=75)
## augment chunk output
opts_chunk$set(echo=T,cache=F, tidy=T,comment=F,message=T,warning=T) #change message/warning to F upon completion
## set table style for consistency
default(kable) <- list(format="html")
default(kable_styling)  <- list(bootstrap_options = "hover",full_width=T, font_size=10)
default(scroll_box) <- list(width = "100%")
matrix_data <- df %>% select(user_id, business_id, stars) %>% mutate(user_id=as.factor(user_id), business_id=as.factor(business_id), stars=as.numeric(stars))
uimat <- as(matrix_data,"realRatingMatrix")
as(uimat,"Matrix")
as(uimat,"matrix")
matrix_data <- df %>% select(userID, itemID, stars)
uimat <- as(matrix_data,"realRatingMatrix")
matrix_data <- df %>% select(userID, itemID, stars) %>% mutate(userID=as.factor(userID), itemID=as.factor(itemID), stars=as.numeric(stars))
uimat <- as(matrix_data,"realRatingMatrix")
matrix_data <- df %>% select(userID, itemID, stars) %>% mutate(userID=as.factor(userID), itemID=as.factor(itemID), stars=as.numeric(stars)) %>% spread(itemID, stars)
matrix_data
#uimat <- as(matrix_data,"realRatingMatrix")
# spread data from long to wide format
matrix_data <- df %>% select(userID, itemID, stars) %>% mutate(userID=as.factor(userID), itemID=as.factor(itemID), stars=as.numeric(stars)) %>% spread(itemID, stars)
# set row names to userid
rownames(matrix_data)<-matrix_data$userID
# remove userid from columns and convert to matrix
uimat <-matrix_data %>% select(-userID) %>% as.matrix()
# store matrix as realRatingMatrix
uimat <- as(uimat,"realRatingMatrix")
matrix_data
# spread data from long to wide format
matrix_data <- df %>% select(userID, itemID, stars) %>% mutate(userID=as.factor(userID), itemID=as.factor(itemID), stars=as.numeric(stars)) %>% spread(itemID, stars)
# set row names to userid
rownames(matrix_data)<-matrix_data$userID
# remove userid from columns and convert to matrix
matrix_data <-matrix_data %>% select(-userID) %>% as.matrix()
# store matrix as realRatingMatrix
uimat <- as(matrix_data,"realRatingMatrix")
matrix_data
# spread data from long to wide format
matrix_data <- df %>% select(userID, itemID, stars) %>% mutate(userID=as.factor(userID), itemID=as.factor(itemID), stars=as.numeric(stars)) %>% spread(itemID, stars)
# set row names to userid
rownames(matrix_data)<-matrix_data$userID
# remove userid from columns
matrix_data <-matrix_data %>% select(-userID)
# convert to matrix
uimat <- matrix_data %>% as.matrix()
# store matrix as realRatingMatrix
uimat <- as(matrix_data,"realRatingMatrix")
# spread data from long to wide format
matrix_data <- df %>% select(userID, itemID, stars) %>% mutate(userID=as.factor(userID), itemID=as.factor(itemID), stars=as.numeric(stars)) %>% spread(itemID, stars)
# set row names to userid
rownames(matrix_data)<-matrix_data$userID
# remove userid from columns
matrix_data <-matrix_data %>% select(-userID)
# convert to matrix
uimat <- matrix_data %>% as.matrix()
# store matrix as realRatingMatrix
uimat <- as(uimat,"realRatingMatrix")
View(uimat)
matrix_data
# spread data from long to wide format
matrix_data <- df %>% select(userID, itemID, stars) %>% spread(itemID, stars)
# set row names to userid
rownames(matrix_data)<-matrix_data$userID
# remove userid from columns
matrix_data <-matrix_data %>% select(-userID)
# convert to matrix
ui_mat <- matrix_data %>% as.matrix()
# store matrix as realRatingMatrix
ui_mat <- as(uimat,"realRatingMatrix")
# view matrix data
matrix_data
#install.packages("devtools")
#devtools::install_github("rstudio/sparklyr")
library(sparklyr)
# Connect to Spark/Hadoop locally
library(sparklyr)
spark_install(version = "2.0.2")
sc <- spark_connect(master = "local")
spark_version(sc)
#install.packages("devtools")
#devtools::install_github("rstudio/sparklyr")
library(sparklyr)
# Connect to Spark/Hadoop locally
library(sparklyr)
spark_install(version = "2.0.2")
sc <- spark_connect(master = "local", version = "2.0.2")
spark_version(sc)
spark_disconnect(sc)
#install.packages("devtools")
#devtools::install_github("rstudio/sparklyr")
library(sparklyr)
# Connect to Spark/Hadoop locally
library(sparklyr)
spark_install(version = "2.0.2")
sc <- spark_connect(master = "local", version = "2.0.2")
spark_version(sc)
spark_data <- user_item_data %>% select(stars, userID, itemID)
spark_data <- df %>% select(stars, userID, itemID)
# Import data to Spark cluster
sprk_df <- sdf_copy_to(sc, spark_data, "sprk_df", overwrite = TRUE)
src_tbls(sc)
fit <- ml_als(sprk_df, rating_col = "stars", user_col = "userID", item_col = "itemID")
spark_disconnect(sc)
