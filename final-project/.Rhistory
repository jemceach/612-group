yelp <- sdf_copy_to(sc, spark_data, "yelp", overwrite = TRUE)
# Transform features
yelp <- yelp %>%
ft_string_indexer(input_col = "user_id", output_col = "user_index") %>%
ft_string_indexer(input_col = "business_id", output_col = "item_index") %>%
select(-user_id, -business_id)%>%
sdf_register("yelp")
# randomly split / train test data
split <- sdf_random_split(yelp, training = 0.8, testing = 0.2, seed=1)
# store training / test sets
train <- sdf_register(split$training, "train")
test <- sdf_register(split$testing, "test")
# tidy train for algoritms that require only user/item inputs
ui_train <- tbl(sc, "train") %>% select(user_index, item_index, stars)
ui_test <- tbl(sc, "test") %>% select(user_index, item_index, stars)
# build model using user/business/ratings
als_fit <- ml_als(tidy_train, max_iter = 5, nonnegative = TRUE,
rating_col = "stars",
user_col = "user_index",
item_col = "item_index")
# build model using user/business/ratings
als_fit <- ml_als(ui_train, max_iter = 5, nonnegative = TRUE,
rating_col = "stars",
user_col = "user_index",
item_col = "item_index")
# predict from the model for the training data
als_predict_train <- ml_predict(als_fit, ui_train)
als_predict_test <- ml_predict(als_fit, ui_test)
# calculate accuracy
als_eval_train <- als_predict_train %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
# build model using user/business/ratings
als_fit <- ml_als(ui_train, max_iter = 5, nonnegative = TRUE,
rating_col = "stars",
user_col = "user_index",
item_col = "item_index")
# predict from the model for the training data
als_predict_train <- ml_predict(als_fit, ui_train)
als_predict_test <- ml_predict(als_fit, ui_test)
# store predictions
als_predict_train <- collect(als_eval_train)
# build model using user/business/ratings
als_fit <- ml_als(ui_train, max_iter = 5, nonnegative = TRUE,
rating_col = "stars",
user_col = "user_index",
item_col = "item_index")
# predict from the model for the training data
als_predict_train <- ml_predict(als_fit, ui_train)
als_predict_test <- ml_predict(als_fit, ui_test)
# store predictions
als_predict_train <- collect(als_predict_train)
als_predict_test <- collect(als_predict_test)
# Remove NaN (result of test/train splits - not data)
als_predict_train <- als_predict_train[!is.na(als_predict_train$prediction), ]
als_predict_test <- als_predict_test[!is.na(als_predict_test$prediction), ]
# Calculate MSE/RMSE/MAE
als_mse_train <- mean((als_predict_train$stars - als_predict_train$prediction)^2)
als_rmse_train <- sqrt(als_mse)
# build model using user/business/ratings
als_fit <- ml_als(ui_train, max_iter = 5, nonnegative = TRUE,
rating_col = "stars",
user_col = "user_index",
item_col = "item_index")
# predict from the model for the training data
als_predict_train <- ml_predict(als_fit, ui_train)
als_predict_test <- ml_predict(als_fit, ui_test)
# store predictions
als_predict_train <- collect(als_predict_train)
als_predict_test <- collect(als_predict_test)
# Remove NaN (result of test/train splits - not data)
als_predict_train <- als_predict_train[!is.na(als_predict_train$prediction), ]
als_predict_test <- als_predict_test[!is.na(als_predict_test$prediction), ]
# Calculate MSE/RMSE/MAE
als_mse_train <- mean((als_predict_train$stars - als_predict_train$prediction)^2)
als_rmse_train <- sqrt(als_mse_train)
als_mae_train <- mean(abs(als_predict_train$stars - als_predict_train$prediction))
als_mse_test <- mean((als_predict_test$stars - als_predict_test$prediction)^2)
als_rmse_test <- sqrt(als_mse_test)
als_mae_test <- mean(abs(als_predict_test$stars - als_predict_test$prediction))
#view
als_predict_test %>% arrange(user_index) %>%
select(-user_index,-item_index) %>%
mutate(prediction=round(prediction)) %>%
head() %>% kable(caption = "Preview of prediction output") %>%
kable_styling()
#view
als_predict_test %>% arrange(user_index) %>%
mutate(prediction=round(prediction)) %>%
head() %>% kable(caption = "Preview of prediction output") %>%
kable_styling()
# build model using user/business index, category, and city
rf_fit <- ml_random_forest(
train, # the training partion
response = "stars",
features = colnames(train)[5:6],
impurity = "entropy",
type = "classification",
seed = 1)
# build model using user/business index, category, and city
rf_fit <- ml_random_forest(
train, # the training partion
response = "stars",
features = colnames(train)[4:5],
impurity = "entropy",
type = "classification",
seed = 1)
# build model using user/business index, category, and city
rf_fit <- ml_random_forest(
train, # the training partion
response = "stars",
features = colnames(train)[2:5],
impurity = "entropy",
type = "classification",
seed = 1)
# build model using user/business index, category, and city
rf_fit <- ml_random_forest(
train, # the training partion
response = "stars",
features = colnames(train)[2:4],
impurity = "entropy",
type = "classification",
seed = 1)
spark_disconnect(sc)
## data processing packages
library(dplyr)
##formatting packages
library(knitr); library(kableExtra); library(default)
##visualization packages
library(ggplot2)
##recommender packages
library(recommenderlab); library(Metrics); library(lsa); library(diveRsity)
## timing script execution
library(tictoc)
##preprocessing data
try(setwd("~/GitHub/612-group/final-project"))
suppressWarnings(source("preprocessing.R"))
# global options
## knit sizing
options(max.print="100"); opts_knit$set(width=75)
## augment chunk output
opts_chunk$set(echo=T,cache=F, tidy=T,comment=F,message=T,warning=T) #change message/warning to F upon completion
## set table style for consistency
default(kable) <- list(format="html")
default(kable_styling)  <- list(bootstrap_options = "hover",full_width=T, font_size=10)
default(scroll_box) <- list(width = "100%")
#preview business
business %>% head() %>% kable(caption="Preview Business Data") %>% kable_styling()
#preview reviews
review %>% select() %>% head(1) %>% kable(caption="Preview Review Data (without Review Text)") %>% kable_styling()
#preview users
user %>% head() %>% kable(caption="Preview User Data") %>% kable_styling()
#preview main df
df %>% select(-text) %>% head() %>% kable(caption="Preview main dataframe") %>% kable_styling()
# spread data from long to wide format
matrix_data <- df %>% select(userID, itemID, stars) %>% spread(itemID, stars)
# set row names to userid
rownames(matrix_data)<-matrix_data$userID
# remove userid from columns
matrix_data <-matrix_data %>% select(-userID)
# convert to matrix
ui_mat <- matrix_data %>% as.matrix()
# store matrix as realRatingMatrix
ui_mat <- as(ui_mat,"realRatingMatrix")
# view matrix data
matrix_data
# evaluation method with 80% of data for train and 20% for test
set.seed(1000)
evalu <- evaluationScheme(ui_mat, method="split", train=0.8, given=1, goodRating=1, k=10)
# Prep data
train <- getData(evalu, 'train')# Training Dataset
dev_test <- getData(evalu, 'known') # Test data from evaluationScheme of type KNOWN
test <- getData(evalu, 'unknown') # Unknow datset used for RMSE / model evaluation
#install.packages("devtools")
#devtools::install_github("rstudio/sparklyr")
#spark_install(version = "2.4.3")
library(sparklyr)
# configure spark connection
config <- spark_config()
config$spark.executor.memory <- "8G"
config$spark.executor.cores <- 2
config$spark.executor.instances <- 3
config$spark.dynamicAllocation.enabled <- "false"
# initiate connection
sc <- spark_connect(master = "local", config=config, version = "2.4.3")
# unhash to verify version:
# spark_version(sc)
# select data for spark and create spark table
spark_data <- df %>% select(stars, user_id, business_id, name, city, categories)
yelp <- sdf_copy_to(sc, spark_data, "yelp", overwrite = TRUE)
# Transform features
yelp <- yelp %>%
ft_string_indexer(input_col = "user_id", output_col = "user_index") %>%
ft_string_indexer(input_col = "business_id", output_col = "item_index") %>%
select(-user_id, -business_id)%>%
sdf_register("yelp")
# randomly split / train test data
split <- sdf_random_split(yelp, training = 0.8, testing = 0.2, seed=1)
# store training / test sets
train <- sdf_register(split$training, "train")
test <- sdf_register(split$testing, "test")
# tidy train for algoritms that require only user/item inputs
ui_train <- tbl(sc, "train") %>% select(user_index, item_index, stars)
ui_test <- tbl(sc, "test") %>% select(user_index, item_index, stars)
# build model using user/business/ratings
als_fit <- ml_als(ui_train, max_iter = 5, nonnegative = TRUE,
rating_col = "stars",
user_col = "user_index",
item_col = "item_index")
# predict from the model for the training data
als_predict_train <- ml_predict(als_fit, ui_train)
als_predict_test <- ml_predict(als_fit, ui_test)
# store predictions
als_predict_train <- collect(als_predict_train)
als_predict_test <- collect(als_predict_test)
# Remove NaN (result of test/train splits - not data)
als_predict_train <- als_predict_train[!is.na(als_predict_train$prediction), ]
als_predict_test <- als_predict_test[!is.na(als_predict_test$prediction), ]
# Calculate MSE/RMSE/MAE
als_mse_train <- mean((als_predict_train$stars - als_predict_train$prediction)^2)
als_rmse_train <- sqrt(als_mse_train)
als_mae_train <- mean(abs(als_predict_train$stars - als_predict_train$prediction))
als_mse_test <- mean((als_predict_test$stars - als_predict_test$prediction)^2)
als_rmse_test <- sqrt(als_mse_test)
als_mae_test <- mean(abs(als_predict_test$stars - als_predict_test$prediction))
# build model using user/business index, category, and city
rf_fit <- ml_random_forest(
train, # the training partion
response = "stars",
features = colnames(train)[2:4],
impurity = "entropy",
type = "classification",
seed = 1)
# identify important features in model
rf_importance1 <- ml_tree_feature_importance(sc = sc, model = rf_fit)
rf_importance2<- rf_importance1 %>% mutate(importance = round(importance,2)) %>% filter(importance>0)
# percent of terms found important
nrow(rf_importance2)/(nrow(rf_importance1) +nrow(rf_importance2))
# view importance
rf_importance2 %>% kable() %>% kable_styling()
# predict from the model for the training data
rf_predict_train <- ml_predict(rf_fit, train) %>% collect()
## data processing packages
library(dplyr)
##formatting packages
library(knitr); library(kableExtra); library(default)
##visualization packages
library(ggplot2)
##recommender packages
library(recommenderlab); library(Metrics); library(lsa); library(diveRsity)
## timing script execution
library(tictoc)
##preprocessing data
try(setwd("~/GitHub/612-group/final-project"))
suppressWarnings(source("preprocessing.R"))
# global options
## knit sizing
options(max.print="100"); opts_knit$set(width=75)
## augment chunk output
opts_chunk$set(echo=T,cache=F, tidy=T,comment=F,message=T,warning=T) #change message/warning to F upon completion
## set table style for consistency
default(kable) <- list(format="html")
default(kable_styling)  <- list(bootstrap_options = "hover",full_width=T, font_size=10)
default(scroll_box) <- list(width = "100%")
#preview business
business %>% head() %>% kable(caption="Preview Business Data") %>% kable_styling()
#preview reviews
review %>% select() %>% head(1) %>% kable(caption="Preview Review Data (without Review Text)") %>% kable_styling()
#preview users
user %>% head() %>% kable(caption="Preview User Data") %>% kable_styling()
#preview main df
df %>% select(-text) %>% head() %>% kable(caption="Preview main dataframe") %>% kable_styling()
# spread data from long to wide format
matrix_data <- df %>% select(userID, itemID, stars) %>% spread(itemID, stars)
# set row names to userid
rownames(matrix_data)<-matrix_data$userID
# remove userid from columns
matrix_data <-matrix_data %>% select(-userID)
# convert to matrix
ui_mat <- matrix_data %>% as.matrix()
# store matrix as realRatingMatrix
ui_mat <- as(ui_mat,"realRatingMatrix")
# view matrix data
matrix_data
# evaluation method with 80% of data for train and 20% for test
set.seed(1000)
evalu <- evaluationScheme(ui_mat, method="split", train=0.8, given=1, goodRating=1, k=10)
# Prep data
train <- getData(evalu, 'train')# Training Dataset
dev_test <- getData(evalu, 'known') # Test data from evaluationScheme of type KNOWN
test <- getData(evalu, 'unknown') # Unknow datset used for RMSE / model evaluation
#install.packages("devtools")
#devtools::install_github("rstudio/sparklyr")
#spark_install(version = "2.4.3")
library(sparklyr)
# configure spark connection
config <- spark_config()
config$spark.executor.memory <- "8G"
config$spark.executor.cores <- 2
config$spark.executor.instances <- 3
config$spark.dynamicAllocation.enabled <- "false"
# initiate connection
sc <- spark_connect(master = "local", config=config, version = "2.4.3")
# unhash to verify version:
# spark_version(sc)
# select data for spark and create spark table
spark_data <- df %>% select(stars, user_id, business_id, name, city, categories)
yelp <- sdf_copy_to(sc, spark_data, "yelp", overwrite = TRUE)
# Transform features
yelp <- yelp %>%
ft_string_indexer(input_col = "user_id", output_col = "user_index") %>%
ft_string_indexer(input_col = "business_id", output_col = "item_index") %>%
select(-user_id, -business_id)%>%
sdf_register("yelp")
# randomly split / train test data
split <- sdf_random_split(yelp, training = 0.8, testing = 0.2, seed=1)
# store training / test sets
train <- sdf_register(split$training, "train")
test <- sdf_register(split$testing, "test")
# tidy train for algoritms that require only user/item inputs
ui_train <- tbl(sc, "train") %>% select(user_index, item_index, stars)
ui_test <- tbl(sc, "test") %>% select(user_index, item_index, stars)
# build model using user/business/ratings
als_fit <- ml_als(ui_train, max_iter = 5, nonnegative = TRUE,
rating_col = "stars",
user_col = "user_index",
item_col = "item_index")
# predict from the model for the training data
als_predict_train <- ml_predict(als_fit, ui_train)
als_predict_test <- ml_predict(als_fit, ui_test)
# store predictions
als_predict_train <- collect(als_predict_train)
als_predict_test <- collect(als_predict_test)
# Remove NaN (result of test/train splits - not data)
als_predict_train <- als_predict_train[!is.na(als_predict_train$prediction), ]
als_predict_test <- als_predict_test[!is.na(als_predict_test$prediction), ]
# Calculate MSE/RMSE/MAE
als_mse_train <- mean((als_predict_train$stars - als_predict_train$prediction)^2)
als_rmse_train <- sqrt(als_mse_train)
als_mae_train <- mean(abs(als_predict_train$stars - als_predict_train$prediction))
als_mse_test <- mean((als_predict_test$stars - als_predict_test$prediction)^2)
als_rmse_test <- sqrt(als_mse_test)
als_mae_test <- mean(abs(als_predict_test$stars - als_predict_test$prediction))
# build model using user/business index, category, and city
rf_fit <- ml_random_forest(
train, # the training partion
response = "stars",
features = colnames(train)[2:4],
impurity = "entropy",
type = "classification",
seed = 1)
# identify important features in model
rf_importance1 <- ml_tree_feature_importance(sc = sc, model = rf_fit)
rf_importance2<- rf_importance1 %>% mutate(importance = round(importance,2)) %>% filter(importance>0)
# percent of terms found important
nrow(rf_importance2)/(nrow(rf_importance1) +nrow(rf_importance2))
# view importance
rf_importance2 %>% kable() %>% kable_styling()
# predict from the model for the training data
rf_predict_train <- ml_predict(rf_fit, train)
rf_predict_train <- collect(rf_predict_train)
# build model using user/business index, category, and city
rf_fit <- ml_random_forest(
train, # the training partion
response = "stars",
features = colnames(train)[2:4],
impurity = "entropy",
type = "classification",
seed = 1)
# identify important features in model
rf_importance1 <- ml_tree_feature_importance(sc = sc, model = rf_fit)
rf_importance2<- rf_importance1 %>% mutate(importance = round(importance,2)) %>% filter(importance>0)
# percent of terms found important
nrow(rf_importance2)/(nrow(rf_importance1) +nrow(rf_importance2))
# view importance
rf_importance2 %>% kable() %>% kable_styling()
# predict from the model for the training data
rf_predict_train <- ml_predict(rf_fit, train)
rf_predict_test <- ml_predict(rf_fit, test)
rf_predict_train <- collect(rf_predict_train)
# predict from the model for the training data
rf_predict_train <- ml_predict(rf_fit, train)
rf_predict_test <- ml_predict(rf_fit, test)
# Remove NaN (result of test/train splits - not data)
rf_predict_train <- rf_predict_train[!is.na(rf_predict_train$prediction), ]
collect(rf_predict_test)
# predict from the model for the training data
rf_predict_train <- ml_predict(rf_fit, train)  %>% collect()
# build model using user/business/ratings
als_fit <- ml_als(ui_train, max_iter = 5, nonnegative = TRUE,
rating_col = "stars",
user_col = "user_index",
item_col = "item_index")
# predict from the model for the training data
als_predict_train <- ml_predict(als_fit, ui_train) %>% collect()
als_predict_test <- ml_predict(als_fit, ui_test) %>% collect()
# Remove NaN (result of test/train splits - not data)
als_predict_train <- als_predict_train[!is.na(als_predict_train$prediction), ]
als_predict_test <- als_predict_test[!is.na(als_predict_test$prediction), ]
# Calculate MSE/RMSE/MAE
als_mse_train <- mean((als_predict_train$stars - als_predict_train$prediction)^2)
als_rmse_train <- sqrt(als_mse_train)
als_mae_train <- mean(abs(als_predict_train$stars - als_predict_train$prediction))
als_mse_test <- mean((als_predict_test$stars - als_predict_test$prediction)^2)
als_rmse_test <- sqrt(als_mse_test)
als_mae_test <- mean(abs(als_predict_test$stars - als_predict_test$prediction))
# build model using user/business index, category, and city
rf_fit <- ml_random_forest(
train, # the training partion
response = "stars",
features = colnames(train)[2:4],
impurity = "entropy",
type = "classification",
seed = 1)
# identify important features in model
rf_importance1 <- ml_tree_feature_importance(sc = sc, model = rf_fit)
rf_importance2<- rf_importance1 %>% mutate(importance = round(importance,2)) %>% filter(importance>0)
# percent of terms found important
nrow(rf_importance2)/(nrow(rf_importance1) +nrow(rf_importance2))
# view importance
rf_importance2 %>% kable() %>% kable_styling()
# predict from the model for the training data
rf_predict_train <- ml_predict(rf_fit, train)  %>% collect()
# build model using user/business index, category, and city
rf_fit <- ml_random_forest(
train, # the training partion
response = "stars",
features = colnames(train)[2:4],
impurity = "entropy",
type = "classification",
seed = 1)
# identify important features in model
rf_importance1 <- ml_tree_feature_importance(sc = sc, model = rf_fit)
rf_importance2<- rf_importance1 %>% mutate(importance = round(importance,2)) %>% filter(importance>0)
# percent of terms found important
nrow(rf_importance2)/nrow(rf_importance1)
# view importance
rf_importance2 %>% kable() %>% kable_styling()
# build model using user/business index, category, and city
rf_fit <- ml_random_forest(
train, # the training partion
response = "stars",
features = colnames(train)[2:4],
impurity = "entropy",
type = "classification",
seed = 1)
# build model using user/business index, category, and city
rf_fit <- ml_random_forest(
train, # the training partion
response = "stars",
features = colnames(train)[2:4],
impurity = "entropy",
type = "classification",
seed = 1)
# identify important features in model
rf_importance1 <- ml_tree_feature_importance(sc = sc, model = rf_fit)
rf_importance2<- rf_importance1 %>% mutate(importance = round(importance,2)) %>% filter(importance>0)
# percent of terms found important
nrow(rf_importance2)/nrow(rf_importance1)
# view importance
rf_importance2 %>% kable() %>% kable_styling()
# calculate accuracy
rf_eval_train <- rf_predict_train %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
rf_eval_test <- rf_eval_test %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
# calculate accuracy
rf_eval_train <- rf_predict_train %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
rf_eval_test <- rf_predict_test %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
# calculate accuracy
rf_eval_train <- rf_predict_train %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
rf_eval_test <- rf_predict_test %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
# make predictions
rf_predict_train <- ml_predict(rf_fit, train)  %>% collect()
# make predictions
rf_predict_train <- ml_predict(rf_fit, train)
rf_predict_test <- ml_predict(rf_fit, test)
# calculate accuracy
rf_eval_train <- rf_predict_train %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
rf_eval_test <- rf_predict_test %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
# make predictions
rf_predict_train <- ml_predict(rf_fit, train)
rf_predict_test <- ml_predict(rf_fit, test)
# calculate accuracy
rf_eval_train <- rf_predict_train %>%
ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
##UNABLE TO GET TEST ACCURACY
#rf_eval_test <- rf_predict_test %>%
#  ml_multiclass_classification_evaluator(label = "stars", metric = "accuracy")
rf_eval_train
# View metrics
als_train_metrics<- cbind(als_rmse_train,als_mse_train, als_mae_train)
## data processing packages
library(dplyr)
##formatting packages
library(knitr); library(kableExtra); library(default)
##visualization packages
library(ggplot2)
##recommender packages
library(recommenderlab); library(Metrics); library(lsa); library(diveRsity)
## Sparklyr
#install.packages("devtools")
#devtools::install_github("rstudio/sparklyr")
#spark_install(version = "2.4.3")
library(sparklyr)
##preprocessing data
suppressWarnings(source("preprocessing.R"))
