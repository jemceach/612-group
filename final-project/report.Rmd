---
title: "report"
author: "Juliann McEachern, Rajwant Mishra,Christina Valore"
date:  " July 16, 2019"
output: 
  html_document:
    theme: flatly
    highlight: pygments
    toc_depth: 2
    df_print: paged
    code_folding: hide
---
# Overview {.tabset .tabset-fade .tabset-pills}

Our project used data from Kaggle's 2013 Yelp Challenge. This challenge included a subset of Yelp data from the metropolitan area of Phoenix, Arizona. Our data takes into account user reviews,ratings, and check-in data for a wide-range of businesses. The four datasets consist of the following observations and variables:

## Business
*  'type': 'business',
*  'business_id': (encrypted business id),
*  'name': (business name),
*  'neighborhoods': [(hood names)],
*  'full_address': (localized address),
*  'city': (city),
*  'state': (state),
*  'latitude': latitude,
*  'longitude': longitude,
*  'stars': (star rating, rounded to half-stars),
*  'review_count': review count,
*  'categories': [(localized category names)]
*  'open': True / False (corresponds to permanently closed, not business hours),

## Review
*  'type': 'review',
*  'business_id': (encrypted business id),
*  'user_id': (encrypted user id),
*  'stars': (star rating),
*  'text': (review text),
*  'date': (date, formatted like '2012-03-14', %Y-%m-%d in strptime notation),
*  'votes': {'useful': (count), 'funny': (count), 'cool': (count)}

## User
Some user profiles are omitted from the data because they have elected not to have public profiles. Their reviews may still be in the data set if they are still visible on Yelp.

*  'type': 'user',
*  'user_id': (encrypted user id),
*  'name': (first name),
*  'review_count': (review count),
*  'average_stars': (floating point average, like 4.31),
*  'votes': {'useful': (count), 'funny': (count), 'cool': (count)}

## Checkin
If there are no checkins for a business, the entire record will be omitted.
*  'type': 'checkin',
*  'business_id': (encrypted business id),
*  'checkin_info' (example of checkin format)
  *  '0-0': (number of checkins from 00:00 to 01:00 on all Sundays),
  *  '1-0': (number of checkins from 01:00 to 02:00 on all Sundays), 
  *  '14-4': (number of checkins from 14:00 to 15:00 on all Thursdays),
  *  '23-6': (number of checkins from 23:00 to 00:00 on all Saturdays)

If there was no checkin for an hour-day block it will not be in the dictionary,

# Getting Started

The following packages were used in `R` to complete our project. 

```{r}
## data processing packages
library(dplyr); library(tidyr);library(jsonlite);library(stringr)

##formatting packages
library(knitr); library(kableExtra); library(default)

##visualization packages
library(ggplot2)

##recommender packages
library(recommenderlab); library(Metrics); library(lsa); library(diveRsity)
```

## Data Aquisition

All the data is multiarray of Json, which means file is a collection of json data. We will use  `stream_in` function, which parses json data line-by-line from our files stored within the data folder of our repository. 

```{r, message=F, warning=F}
# Business Data 
business<-stream_in(file("data/yelp_training_set_business.json"),verbose = F)
# user Data 
user <-stream_in(file("data/yelp_training_set_user.json"),verbose = F)
# checkin Data 
checkin <-stream_in(file("data/yelp_training_set_checkin.json"),verbose = F)
# review  Data 
review <-stream_in(file("data/yelp_training_set_review.json"),verbose = F)
```


## Data Transformations {.tabset .tabset-fade .tabset-pills}

### Business

We choose to limit the scope to our recommender system to only businesses with tags related to food and beverages. There were originally 508 unique category tags listed within our business data. We manually filtered 112 targeted categories to subset our data. 

We applied additional transformation to remove unnessacary data. There were 1224 business in our data that were permanently closed. These companies accounted for 9.8% of all businesses, which were subsequently removed from our data. There were also 3 businesses in our dataset from outside of AZ that we allso removed. 

```{r, warning=F, comment=F}
# dropped open, neighborhoods(no data), full address, and review count, type (all business)
df_business<-business %>% filter(open == "TRUE", state=="AZ") %>% select(-open, -neighborhoods, -full_address, -review_count, -type, -stars) %>% mutate(categories = sapply(categories, toString)) 

# create category filter
filter <- 'Argentine| Burmese| Cambodian| Cocktail Bars|Laotian|Lebanese|Live/Raw Food|Russian|African|Champagne Bars|Kosher|Modern European|Scandinavian|Taiwanese|Tapas/Small Plates|Afghan|Brazilian|Food Trucks|Shaved Ice|Wineries|Dim Sum|Ethiopian|Fondue|Hookah Bars|Persian/Iranian|Peruvian| Polish| Seafood Markets| Tapas Bars|Halal|British| Cheese Shops|German|Spanish|Cheesesteaks|Cuban|Do-It-Yourself Food|Gastropubs|Salad|Creperies|Soup|Chocolatiers & Shops|Filipino|Food Stands|Fruits & Veggies|Meat Shops|Mongolian|Soul Food|Comfort Food| Irish|Fish & Chips|Cajun/Creole|Caribbean|Pakistani|Southern|Candy Stores|Vegan|Latin American|Breweries|French|Gay Bars|Korean|Gluten-Free|Hawaiian|Farmers Market|Vegetarian|Middle Eastern|Ethnic Food|Indian|Pubs|Chicken Wings|Dive Bars| Juice Bars & Smoothies|Vietnamese|Cafes|Wine Bars|Bagels|Diners|Hot Dogs|Tex-Mex|Donuts|Greek|Thai| Desserts|Mediterranean|Beer| Wine & Spirits|Seafood|Sushi Bars| Lounges|Steakhouses|Buffets|Japanese|Sports Bars|Delis|Bakeries|Specialty Food|Breakfast & Brunch|Ice Cream & Frozen Yogurt|Burgers|Italian| Chinese|Coffee & Tea|American (New)|Sandwiches|Fast Food|Pizza|American (Traditional)|Bars|Mexican|Food| Restaurants'

# filter businesses using filter & factor categories
df_business <- df_business %>% filter(str_detect(categories, filter)) %>% mutate(categories = as.factor(categories))
```

As a result of our transformations, our recommender data now consists of 4828 unique businesses. This data is previewed below: 

```{r, echo=F}
#preview business
df_business %>% head() %>% kable(caption="Preview Business Data") %>% kable_styling()
```

The graphs below show geographic trends in our data as well as our most popular categories. 

```{r}
# All Business City
df_business %>% select (business_id, city) %>% group_by(city) %>% dplyr::summarise(Count=n()) %>%   ggplot(aes(x = city, y = Count)) +
         geom_bar(stat = "identity") +
          theme(axis.text.x=element_text(angle=90, hjust=1))+
    xlab(label = "Business City")+
  geom_text(aes(label = Count), colour = "blue", fontface = "bold" ,position = position_stack(vjust = 1.1),check_overlap=TRUE)


# All Business City by Focus Category

## add graph later
  
```


### Review
We subset our review data from the subset of food and beverage businesses. This dropped our review data from 229,907 to 165,823 reviews. 

```{r}
#subset reviews & remove columns (type)
df_review <- review %>% filter(business_id %in% df_business$business_id)%>% select(-type)

# assemble ratings data (funny/useful/cool) into singular columns.
df_review <- do.call(data.frame, df_review)

# remove factor from user_id
df_review$user_id <- as.character(df_review$user_id)
df_review$business_id <- as.character(df_review$business_id)
```

```{r, echo=F}
#preview reviews
df_review %>% head() %>% kable(caption="Preview Review Data") %>% kable_styling()
```

Include plot showing something like number of reviews for each business. Review date by month is pretty consistant and not telling of much on its own. 

```{r, echo=F}
library(lubridate)
# Avg Rating Given by User
df_review %>% select (stars,date) %>% 
  mutate(month = month(as_date(date))) %>% group_by(month) %>% 
  dplyr::summarise(Count=n()) %>%  
  ggplot(aes ( x= factor(month),y = Count)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x=element_text(angle=00, hjust=1))+
  xlab(label = "Avg Rating Given by User")


str_split(df_review$rev_date[1],"-",n=3,simplify = TRUE)[2]
```

### User 

We applied a similar filter to users to subset our data based on only our selected businesses. This decreased our user data from 43,873 to 35,268 distinct user_id observations. 
```{r, echo=F}
#subset user & remove columns (type)
df_user <- user %>% filter(user_id %in% df_review$user_id) %>% select(-type)

# assemble ratings data (funny/useful/cool) into singular columns.
df_user <- do.call(data.frame, df_user)
```

The dataframe preview below shows aggregate user data for all reviews an individual user provided for yelp within our data selection. 

```{r, echo=F}
#preview users
df_user %>% head() %>% kable(caption="Preview User Data") %>% kable_styling()
```

The plot below shows the distribution of our average ratings given by all users. 
```{r, echo=F}
# Avg Rating Given by User
df_user %>% select (user_id,average_stars,review_count) %>%
  ggplot(aes(x = round(average_stars), y = review_count)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x=element_text(angle=00, hjust=1))+
  xlab(label = "Avg Rating Given by User")
```

### Checkins

Lastly, we evaluated our checkins data and applied our business filter once more. This decreased our checkin observations from 8282 to 4423. This change tells us that no checkin data is available for 8.4% of businesses in our subset. 

```{r, echo=F}
#subset checkin & remove columns (type)
df_checkin <- checkin %>% filter(business_id %in% df_business$business_id) %>% select(-type)

# unpack checkin_info into singular columns.
### there are 168 checkin column variables. wait to see how data is used before unpacking with do.call.
#df_checkin <- do.call(data.frame, df_user)
```

```{r, echo=F}
#preview users
df_checkin %>% head() 

### unable to apply kable style without unpacking checkin_info TBD
```

## Merge Data 

Next, we created our main dataframe business and review dataframes using the `Business_ID` and `User_ID` as unique keys. This dataframe will be referenced later on when building our recommender matrices and algorithms. 

```{r}
df_main <-df_business %>% inner_join(df_review, by="business_id")
```

```{r, echo=F}
#preview main df
df_main %>% head() 
```


## Matrix Building 

We converted our raw ratings data into a user-item matrix to test and train our subsequent recommender system algorithms. The matrix was saved as a realRatingMatrix for processing purposes later on using the `recommenderlab` package. 

```{r}
matrix_data <- main_df %>% select(user_id, business_id, stars) %>% mutate(user_id=as.factor(user_id), business_id=as.factor(business_id), stars=as.numeric(stars))

ui_mat <- as(matrix_data, "realRatingMatrix")
```

```{r, echo=F}

# make wide df for matrix by spreading business id on stars 
mat_test <- matrix_data %>% group_by(user_id) %>% spread(business_id, stars)


mat_test
```


## Training and Test Subsets

Finally, our data was split into training and tests sets for model evaluation of both two recommender algorithms. We split our data with 10 k-folds using the `recommendaerlab` package. 80% of data was retained for training and 20% for testing purposes.

```{r train-test}
# evaluation method with 90% of data for train and 10% for test
set.seed(1000)

evalu <- evaluationScheme(real_ui_matrix_star, method="split", train=0.5, given=0)

# Prep data
ratings_train <- getData(evalu, 'train')# Training Dataset 
ratings_test_known <- getData(evalu, 'known') # Test data from evaluationScheme of type KNOWN
ratings_test_unknown <- getData(evalu, 'unknown') # Unknow datset used for RMSE / model evaluation

```



## Algorithm{.tabset .tabset-fade .tabset-pills}
### User and Item 
```{r}
# I am planning to see how I can use Business's rating and rev_funny,rev_useful,rev_cool
# and see how users are rating against these parameters, I would check cosine similarlty of user 
# rating with these info and recommend some similar  Business to the Users.


head(df_review[,c(7,8,9,10)])
```



## Conclusion {.tabset .tabset-fade .tabset-pills} 

## Accuracy Metrics {.tabset .tabset-fade .tabset-pills}

# References
* [**Tidyr Issue**](https://github.com/tidyverse/tidyr/issues/426)
* [**Data Overview**](https://www.kaggle.com/c/yelp-recsys-2013/overview)



```{r}

```

<hr><hr>
